{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd67d40b-153d-446e-b6c1-79e0b9bfe34b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "43bdd465-09af-484b-9c80-261e95f3e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from resources.data_utils import peak_to_ring_num, scale_dataset, get_RFP_type \n",
    "from resources.plot_utils import plot_R2, plot_profiles_peak_1channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "754ee386-9d17-467c-b0d6-1ff410bbdd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "481b4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run MLP_VAE_core.ipynb\n",
    "%run VAE_core.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5ce069-5a3c-46eb-8efa-ca17c8f7ea10",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772412ca-56eb-4686-ba79-e5b21b78c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in training data\n",
    "data_dir = \"/data/\"\n",
    "output_dir = data_dir + 'model/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load 1D profiles\n",
    "data_array = np.load(os.path.join(data_dir, 'all_outputs.npy'))\n",
    "data_array = data_array.reshape([-1, 3, 201])\n",
    "RFP_data = data_array[:, 1, :].squeeze()\n",
    "\n",
    "# Normalize RFP\n",
    "normalized_RFP = RFP_data / RFP_data.max(axis=1, keepdims=True)\n",
    "normalized_RFP = normalized_RFP.reshape([-1, 1, 201])\n",
    "\n",
    "# Parameters \n",
    "params_array = np.load(os.path.join(data_dir + 'all_params.npy' ))\n",
    "scaling_ranges = {\n",
    "    'DC': [0.5e-3, 12.5e-2],\n",
    "    'aC': [0.1, 1],\n",
    "    'aA': [100, 100000],\n",
    "    'aT': [10, 8000],\n",
    "    'aL': [5, 500],\n",
    "    'dA': [0.001, 0.1],\n",
    "    'dT': [3, 300],\n",
    "    'dL': [0.144, 14.4],\n",
    "    'alpha': [1, 5],\n",
    "    'beta':  [2, 2000],\n",
    "    'Kphi':  [1, 10],\n",
    "    'N0':  [200000, 5000000]\n",
    "}\n",
    "scaling_options = ['exp','linear','exp','exp','exp',\n",
    "                   'exp','exp','exp','linear','exp',\n",
    "                   'linear','linear']\n",
    "all_params = ['DC', 'DN', 'DA', 'DB', 'aC','aA', 'aB', 'aT', 'aL', 'bN','dA', 'dB', 'dT', 'dL', 'k1', \n",
    "              'k2', 'KN', 'KP', 'KT', 'KA', 'KB', 'alpha','beta', 'Cmax', 'a', 'b', 'm', 'n', 'Kphi', 'l', \n",
    "              'N0', 'G1','G2','G3','G4','G5','G6','G7','G8','G9','G10','G11','G12', 'G13','G14',\n",
    "             'G15','G16','G17','G18', 'G19', 'alpha_p','beta_p', 'seeding_v']\n",
    "sceening_params = ['DC',  'aC', 'aA', 'aT', 'aL', 'dA','dT', 'dL', 'alpha','beta','Kphi', 'N0']\n",
    "selected_param_idx = [all_params.index(param) for param in sceening_params]\n",
    "params_array = params_array[:, selected_param_idx]\n",
    "\n",
    "# Pattern types\n",
    "pattern_types_array = np.load(os.path.join(data_dir, 'all_types.npy'))\n",
    "RFP_types_array = pattern_types_array[:, 1]\n",
    "\n",
    "# Check size\n",
    "print('---------------------------------------------')\n",
    "print(f\"RFP profiles: {normalized_RFP.shape}\")\n",
    "print(f\"Parameters: {params_array.shape}\")\n",
    "print(f\"Pattern types:  {RFP_types_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44864f13-361a-4379-8148-a93799a23ada",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662a8dd-b864-49da-90d1-39ce72ab2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up hyperparameters\n",
    "batch_size = 32\n",
    "latent_dim = 16\n",
    "latent_channel = 16 \n",
    "seq_length = normalized_RFP.shape[2] \n",
    "input_dim = params_array.shape[1]\n",
    "\n",
    "# Set everything to float32\n",
    "normalized_RFP = normalized_RFP.astype(np.float32)\n",
    "params_array = params_array.astype(np.float32)\n",
    "\n",
    "# Shuffle\n",
    "normalized_RFP = shuffle(normalized_RFP, random_state=25)\n",
    "params_array = shuffle(params_array, random_state=25)\n",
    "RFP_types_array = shuffle(RFP_types_array, random_state=25)\n",
    "\n",
    "\n",
    "# Split datasets\n",
    "ratio = 0.1\n",
    "train_data, test_data, train_indices, test_indices = train_test_split(normalized_RFP, range(len(normalized_RFP)), test_size=ratio, random_state=42, shuffle=False)\n",
    "train_params, test_params, train_indices, test_indices = train_test_split(params_array, range(len(params_array)), test_size=ratio, random_state=42, shuffle=False)\n",
    "train_types, test_types, train_indices, test_indices = train_test_split(RFP_types_array, range(len(RFP_types_array)), test_size=ratio, random_state=42, shuffle=False)\n",
    "\n",
    "train_data, valid_data, train_indices, valid_indices = train_test_split(train_data, range(len(train_data)), test_size=ratio, random_state=42, shuffle=False)\n",
    "train_params, valid_params, train_indices, valid_indices = train_test_split(train_params, range(len(train_params)), test_size=ratio, random_state=42, shuffle=False)\n",
    "train_types, valid_types, train_indices, valid_indices = train_test_split(train_types, range(len(train_types)), test_size=ratio, random_state=42, shuffle=False)\n",
    "\n",
    "# Inputs\n",
    "norm_train_params = scale_dataset(train_params, scaling_ranges, scaling_options)\n",
    "norm_valid_params = scale_dataset(valid_params, scaling_ranges, scaling_options)\n",
    "norm_test_params = scale_dataset(test_params, scaling_ranges, scaling_options)\n",
    "\n",
    "# Dataset\n",
    "train_dataset = CustomDataset(norm_train_params, train_data, train_types)\n",
    "valid_dataset = CustomDataset(norm_valid_params, valid_data, valid_types)\n",
    "test_dataset = CustomDataset(norm_test_params, test_data, test_types)\n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(' -------------------- Train set -------------------- ')\n",
    "print('Data: ', train_data.shape)\n",
    "print('Parameters: ', train_params.shape)\n",
    "print('Pattern type: ', train_types.shape)\n",
    "\n",
    "print(' -------------------- Validation set -------------------- ')\n",
    "print('Data: ', valid_data.shape)\n",
    "print('Parameters: ', valid_params.shape)\n",
    "print('Pattern type: ', valid_types.shape)\n",
    "\n",
    "print(' -------------------- Test set -------------------- ')\n",
    "print('Data: ', test_data.shape)\n",
    "print('Parameters: ', test_params.shape)\n",
    "print('Pattern type: ', test_types.shape)\n",
    "\n",
    "print(' -------------------- Check params ranges -------------------- ')\n",
    "# check parameter ranges\n",
    "upper_lims = np.max(norm_train_params, axis=0)\n",
    "lower_lims = np.min(norm_train_params, axis=0)\n",
    "for i in range(len(upper_lims)):\n",
    "    print(sceening_params[i], ' -- Upper limits -- ',upper_lims[i], 'Lower limits -- ',lower_lims[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9720dd5-e398-450d-920d-52d63a884abb",
   "metadata": {},
   "source": [
    "# Train MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2bb3ec-7400-4726-846b-12f9cf4043e6",
   "metadata": {},
   "source": [
    "## Load trained VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec078c59-a196-4dde-9e39-0ad4f6eb70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(seq_length, latent_dim, latent_channel)\n",
    "filename = output_dir + 'VAE.pt'\n",
    "print(filename)\n",
    "vae.load_state_dict(torch.load(filename))\n",
    "vae = vae.to(device)\n",
    "vae.eval() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22021096-caab-4eb9-805c-6af51b031c0c",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5626263-7c19-4e7e-871f-b48787d7e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate model\n",
    "model = CombinedModel(input_dim, latent_dim, vae.decoder, 42)\n",
    "\n",
    "# # Load trained model if exist\n",
    "# filename = output_dir + 'MLP_VAE.pt'\n",
    "# model.load_state_dict(torch.load(filename))\n",
    "\n",
    "# Freeze VAE parameters\n",
    "for param in model.decoder.parameters():\n",
    "    param.requires_grad = False\n",
    "print(model)\n",
    "model = model.to(device)\n",
    "print(\"The model has\", count_parameters(model), \"trainable parameters\")\n",
    "\n",
    "# Training setup\n",
    "lr = 1e-3           \n",
    "min_lr = 1e-7     \n",
    "epochs = 1000\n",
    "gamma = 0.98\n",
    "weight_decay = 1e-5\n",
    "alpha = 0 # 2e-5 \n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.mlp.parameters(), lr= lr, weight_decay=weight_decay)  \n",
    "\n",
    "# Early stopping \n",
    "best_valid_loss = np.inf  \n",
    "epochs_no_improve = 0  \n",
    "patience = 30 \n",
    "\n",
    "# Warm up\n",
    "warmup_epochs = 10\n",
    "def warmup_scheduler(epoch):\n",
    "    if epoch < warmup_epochs:\n",
    "        return (epoch + 1) / warmup_epochs\n",
    "    else:\n",
    "        return 1.0\n",
    "scheduler1 = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=warmup_scheduler)\n",
    "scheduler2 = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "train_loss_history = []\n",
    "valid_loss_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss = train_combined(model, train_loader, optimizer, criterion, alpha, device)\n",
    "    valid_loss = validate_combined(model, valid_loader, criterion, alpha, device)\n",
    "    test_loss = test_combined(model, test_loader, criterion, alpha, device)\n",
    "    \n",
    "    train_loss_history.append(train_loss)\n",
    "    valid_loss_history.append(valid_loss)\n",
    "    test_loss_history.append(test_loss)\n",
    "\n",
    "    # Clamp minimum learning rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = max(param_group['lr'], min_lr)\n",
    "\n",
    "    # Print loss\n",
    "    if (epoch + 1) % 5 == 0: # every 5 epochs\n",
    "        print('Epoch: {} Train: {:.7f}, Valid: {:.7f}, Test: {:.7f}, Lr:{:.8f}'.format(epoch + 1, train_loss_history[epoch], valid_loss_history[epoch], test_loss_history[epoch], param_group['lr']))\n",
    "    \n",
    "    # Update learning rate\n",
    "    if epoch < warmup_epochs:\n",
    "        scheduler1.step()\n",
    "    else:\n",
    "        scheduler2.step()\n",
    "\n",
    "    # Check for early stopping\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        epochs_no_improve = 0  # Reset the counter\n",
    "    else:\n",
    "        epochs_no_improve += 1  # Increment the counter\n",
    "\n",
    "    if epochs_no_improve == patience:\n",
    "        print('Early stopping!')\n",
    "        break  # Exit the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5236a2b-f3d1-4d6b-9607-042a50b28d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the loss history\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.semilogy(train_loss_history, label='Training')\n",
    "plt.semilogy(valid_loss_history, label='Validation')\n",
    "plt.semilogy(test_loss_history, label='Testing')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8784a347",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19579cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(output_dir,\"MLP_VAE.pt\")\n",
    "print(model_path)\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff467bd5-054e-4252-a3fe-0cb42c0b1bb8",
   "metadata": {},
   "source": [
    "# Training results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310f3aa-acd3-48e5-aa1a-b013b01b6a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = []\n",
    "train_ori = []\n",
    "test_pred = []\n",
    "test_ori = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for params, data, _ in train_loader:\n",
    "        data = data.to(device)\n",
    "        params = params.to(device)\n",
    "        reconstruction, mean, logvar = model(params)\n",
    "        train_pred.append(reconstruction.cpu().numpy())\n",
    "        train_ori.append(data.cpu().numpy())\n",
    "\n",
    "    for params, data, _ in test_loader:\n",
    "        data = data.to(device)\n",
    "        params = params.to(device)\n",
    "        reconstruction, mean, logvar = model(params)\n",
    "        test_pred.append(reconstruction.cpu().numpy())\n",
    "        test_ori.append(data.cpu().numpy())\n",
    "\n",
    "# Concatenate\n",
    "train_pred = np.concatenate(train_pred)#.flatten()\n",
    "train_ori = np.concatenate(train_ori)#.flatten()\n",
    "test_pred = np.concatenate(test_pred)#.flatten()\n",
    "test_ori = np.concatenate(test_ori)#.flatten()\n",
    "\n",
    "filename = output_dir + 'VAE_train_R2.png'\n",
    "plot_R2(train_ori, train_pred, filename)\n",
    "filename = output_dir + 'VAE_test_R2.png'\n",
    "plot_R2(test_ori, test_pred, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329f651",
   "metadata": {},
   "source": [
    "# Accuracy by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeeda99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2_acc_by_type(ori_types, pred_types, ori_data, pred_data, target_class):\n",
    "\n",
    "    # Compute accuracy\n",
    "    filtered_pred_types = [(p, l) for p, l in zip(pred_types, ori_types) if l == target_class]\n",
    "    correct_predictions = sum(p == l for p, l in filtered_pred_types)\n",
    "    total_predictions = len(filtered_pred_types)    \n",
    "\n",
    "    if total_predictions > 0:\n",
    "        accuracy = correct_predictions / total_predictions \n",
    "    else:\n",
    "        accuracy = 0\n",
    "\n",
    "\n",
    "    # Compute R2\n",
    "    indices = [i for i, t in enumerate(ori_types) if t == target_class]\n",
    "\n",
    "    ori_data_selected = ori_data[indices]\n",
    "    pred_data_selected = pred_data[indices]\n",
    "    \n",
    "    if len(ori_data_selected) != 0:\n",
    "        ori_data_selected = ori_data_selected.flatten()\n",
    "        pred_data_selected = pred_data_selected.flatten()\n",
    "\n",
    "        r2 = r2_score(ori_data_selected, pred_data_selected)\n",
    "    else:\n",
    "        r2 = 0\n",
    "        \n",
    "    return r2, accuracy, correct_predictions, total_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e10204",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' ------------------------- Train ------------------------- ')\n",
    "_, ori_types = get_RFP_type(train_ori)\n",
    "_, pred_types = get_RFP_type(train_pred)\n",
    "ori_types = peak_to_ring_num(np.array(ori_types))\n",
    "pred_types = peak_to_ring_num(np.array(pred_types))\n",
    "\n",
    "\n",
    "# Get R2 and acc for each pattern type\n",
    "R2_1, acc_1, correct_1, total_1 = R2_acc_by_type(ori_types, pred_types, train_ori, train_pred, 1)\n",
    "R2_2, acc_2, correct_2, total_2 = R2_acc_by_type(ori_types, pred_types, train_ori, train_pred, 2)\n",
    "R2_3, acc_3, correct_3, total_3 = R2_acc_by_type(ori_types, pred_types, train_ori, train_pred, 3)\n",
    "R2_4, acc_4, correct_4, total_4 = R2_acc_by_type(ori_types, pred_types, train_ori, train_pred, 4)\n",
    "\n",
    "print(' 1 ring --- R2: ', R2_1, ' , acc: ', acc_1 , ', correct#: ', correct_1, ', total#: ', total_1)\n",
    "print(' 2 ring --- R2: ', R2_2, ' , acc: ', acc_2 , ', correct#: ', correct_2, ', total#: ', total_2)\n",
    "print(' 3 ring --- R2: ', R2_3, ' , acc: ', acc_3 , ', correct#: ', correct_3, ', total#: ', total_3)\n",
    "print(' 4 ring --- R2: ', R2_4, ' , acc: ', acc_4 , ', correct#: ', correct_4, ', total#: ', total_4)\n",
    "\n",
    "print(' ------------------------- Test ------------------------- ')\n",
    "_, ori_types = get_RFP_type(test_ori)\n",
    "_, pred_types = get_RFP_type(test_pred)\n",
    "ori_types = peak_to_ring_num(np.array(ori_types))\n",
    "pred_types = peak_to_ring_num(np.array(pred_types))\n",
    "\n",
    "# Get R2 and acc for each pattern type\n",
    "R2_1, acc_1, correct_1, total_1 = R2_acc_by_type(ori_types, pred_types, test_ori, test_pred, 1)\n",
    "R2_2, acc_2, correct_2, total_2 = R2_acc_by_type(ori_types, pred_types, test_ori, test_pred, 2)\n",
    "R2_3, acc_3, correct_3, total_3 = R2_acc_by_type(ori_types, pred_types, test_ori, test_pred, 3)\n",
    "R2_4, acc_4, correct_4, total_4 = R2_acc_by_type(ori_types, pred_types, test_ori, test_pred, 4)\n",
    "\n",
    "print(' 1 ring --- R2: ', R2_1, ' , acc: ', acc_1 , ', correct#: ', correct_1, ', total#: ', total_1)\n",
    "print(' 2 ring --- R2: ', R2_2, ' , acc: ', acc_2 , ', correct#: ', correct_2, ', total#: ', total_2)\n",
    "print(' 3 ring --- R2: ', R2_3, ' , acc: ', acc_3 , ', correct#: ', correct_3, ', total#: ', total_3)\n",
    "print(' 4 ring --- R2: ', R2_4, ' , acc: ', acc_4 , ', correct#: ', correct_4, ', total#: ', total_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef27fd-1d6b-4007-9cfd-c852b375b10d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot examples\n",
    "for i in range(0, 5):\n",
    "    plot_profiles_peak_1channel(test_pred[i].squeeze())\n",
    "    plot_profiles_peak_1channel(test_ori[i].squeeze())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
