{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd67d40b-153d-446e-b6c1-79e0b9bfe34b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43bdd465-09af-484b-9c80-261e95f3e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from resources.data_utils import get_RFP_type_single, check_smoothness_dataset, peak_to_ring_num, random_sampling, check_smoothness, get_RFP_type, scale_dataset, scaleback_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1b75f0-b467-481c-a2a1-3bfa9f78eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run VAE_core.ipynb\n",
    "%run MLP_VAE_core.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd629b5-5af8-4d1e-b8b9-d5cab425ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69913706-96fa-41a8-be96-5040dcec7ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average_filter(data, window_size):\n",
    "    half_window = window_size // 2\n",
    "    length = data.shape[0]\n",
    "    smoothed_data = np.zeros(length)\n",
    "    \n",
    "    # Handle center cases\n",
    "    smoothed_data[:half_window] = data[:half_window]\n",
    "    \n",
    "    # Apply the moving average filter for the middle sequences\n",
    "    for i in range(half_window, length - half_window):\n",
    "        window = data[i - half_window: i + half_window + 1]\n",
    "        smoothed_data[i] = window.mean()\n",
    "    \n",
    "    # Handle boundary cases\n",
    "    smoothed_data[length - half_window:] = data[length - half_window:]\n",
    "    \n",
    "    return smoothed_data\n",
    "\n",
    "def remove_rand_peaks(data, zero_threshold=0, min_zero_length=20, peak_threshold=0.05):\n",
    "    filtered_data = np.copy(data)\n",
    "    found_zero_chunk = False\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if i + min_zero_length <= len(data) and np.all(filtered_data[i:i + min_zero_length] <= zero_threshold):\n",
    "            \n",
    "            # Check if there's a peak in the chunk that exceeds peak_threshold\n",
    "            if np.any(filtered_data[i:i + min_zero_length] > peak_threshold):\n",
    "                # If peak exists, continue searching for a valid zero chunk\n",
    "                continue  \n",
    "\n",
    "            else:\n",
    "                # Found a valid zero chunk without significant peaks\n",
    "                start_index = i\n",
    "                found_zero_chunk = True\n",
    "                break\n",
    "\n",
    "    if found_zero_chunk: #remove rand peak\n",
    "        filtered_data[start_index:] = 0\n",
    "\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1cb95c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ML_by_type(idx, num_pattern, target_idx_list, all_ML_outputs, all_params, target_ring_num, output_dir):\n",
    "    # target_ring_num: wanted ring number\n",
    "    # all_ML_outputs: ML predictions\n",
    "    # all_params: random parameters\n",
    "    # num_pattern: max number of data points to collect\n",
    "    # idx: file ID\n",
    "    # target_idx_list: index list of target class\n",
    "\n",
    "    outputs = []\n",
    "    params = []\n",
    "    types = []\n",
    "\n",
    "    count = 0\n",
    "    for i in target_idx_list:\n",
    "        count += 1\n",
    "        data = all_ML_outputs[i, 0, :]\n",
    "        param = np.array(all_params[i])\n",
    "        _, RFP_type = get_RFP_type_single(data)\n",
    "\n",
    "        # Check smoothness\n",
    "        if_smooth, _ = check_smoothness(data)\n",
    "        if (data[-1] > 0.05 * np.max(data)):\n",
    "            if_smooth = 0\n",
    "\n",
    "        if if_smooth == 1: # if data is smooth\n",
    "            # Append data point \n",
    "            outputs.append(np.array(data))\n",
    "            params.append(np.array(param))\n",
    "            types.append(np.array(RFP_type))\n",
    "\n",
    "            # Break if got enough data points\n",
    "            if len(outputs) == num_pattern:\n",
    "                break\n",
    "\n",
    "    # Save temp files\n",
    "    filename = output_dir + str(target_ring_num) + '_rings_outputs_' + str(idx) +'.npy'\n",
    "    np.save(filename, np.array(outputs))\n",
    "    filename = output_dir + str(target_ring_num) + '_rings_params_' + str(idx) +'.npy'\n",
    "    np.save(filename, np.array(params))\n",
    "    filename = output_dir + str(target_ring_num) + '_rings_types_' + str(idx) +'.npy'\n",
    "    np.save(filename, np.array(types))\n",
    "\n",
    "def concatenate_temps_by_type(idx, num_pattern, target_ring_num, col_names, output_dir):\n",
    "    all_outputs = []\n",
    "    all_params = []\n",
    "    all_types = []\n",
    "\n",
    "    for i in range(1, idx+1): \n",
    "\n",
    "        # Outputs\n",
    "        filename = output_dir + f'{target_ring_num}_rings_outputs_{i}.npy'\n",
    "        if not os.path.exists(filename): # Skip if file doesn't exist\n",
    "            continue\n",
    "            \n",
    "        arr = np.load(filename)\n",
    "        if len(arr) == 0: # If it's empty\n",
    "            continue\n",
    "        all_outputs.append(arr)\n",
    "\n",
    "        # Parameters\n",
    "        filename = output_dir + f'{target_ring_num}_rings_params_{i}.npy'\n",
    "        all_params.append(np.load(filename))\n",
    "\n",
    "        # Pattern types\n",
    "        filename = output_dir + f'{target_ring_num}_rings_types_{i}.npy'\n",
    "        all_types.append(np.load(filename, allow_pickle=True))\n",
    "    \n",
    "    # If any is empty, skip\n",
    "    if not all_outputs or not all_params or not all_types:\n",
    "        print(f\"{target_ring_num} ring -- Empty file\")\n",
    "        return 0, pd.DataFrame(columns=col_names)\n",
    "\n",
    "    # Concatenate results\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_params = np.concatenate(all_params)\n",
    "    all_types = np.concatenate(all_types)\n",
    "    \n",
    "    # df\n",
    "    target_df = pd.DataFrame(all_params, columns=col_names)\n",
    "    target_df['RFP_type'] = all_types # peak number\n",
    "    target_df = target_df.head(num_pattern)\n",
    "\n",
    "    # Save\n",
    "    print(target_ring_num, ' ring -- ', len(all_types))\n",
    "    filename = output_dir + str(target_ring_num) + '_rings_outputs.npy'\n",
    "    np.save(filename, np.array(all_outputs)[0: num_pattern])\n",
    "    filename = output_dir + str(target_ring_num) + '_rings_params.npy'\n",
    "    np.save(filename, np.array(all_params)[0: num_pattern])\n",
    "    filename = output_dir + str(target_ring_num) + '_rings_types.npy'\n",
    "    np.save(filename, np.array(all_types)[0: num_pattern])\n",
    "\n",
    "    return len(all_outputs), target_df, all_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5ce069-5a3c-46eb-8efa-ca17c8f7ea10",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sampling setup and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "020422bc-a28f-4931-a651-048e9ed92b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./all_data/\"\n",
    "output_dir = data_dir + \"inference_1/\" \n",
    "model_dir = './model/'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "134d6f33-53f3-4db7-a3e4-5a941acd43ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling setup\n",
    "scaling_ranges = {\n",
    "    'DC': [0.5e-3, 12.5e-2],\n",
    "    'aC': [0.1, 1],\n",
    "    'aA': [100, 100000],\n",
    "    'aT': [10, 8000],\n",
    "    'aL': [5, 500],\n",
    "    'dA': [0.001, 0.1],\n",
    "    'dT': [3, 300],\n",
    "    'dL': [0.144, 14.4],\n",
    "    'alpha': [1, 5],\n",
    "    'beta':  [2, 2000],\n",
    "    'Kphi':  [1, 10],\n",
    "    'N0':  [200000, 5000000]\n",
    "}\n",
    "scaling_options = ['exp','linear','exp','exp','exp', 'exp','exp','exp','linear','exp','linear','linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf9284e-322b-4703-af62-bbc15e4486f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "input_dim = 12\n",
    "seq_length = 201\n",
    "batch_size = 32\n",
    "latent_dim = 16\n",
    "latent_channel = 16\n",
    "\n",
    "# Load trained model\n",
    "# Initiate VAE\n",
    "vae = VAE(seq_length, latent_dim, latent_channel)\n",
    "filename = model_dir + 'VAE.pt'\n",
    "# Initiate MLP\n",
    "model = CombinedModel(input_dim, latent_dim, vae.decoder, 42) \n",
    "filename = os.path.join(model_dir, \"MLP_VAE.pt\")\n",
    "# Load trained model\n",
    "model.load_state_dict(torch.load(filename))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd56f6a-f5c6-453c-abe0-bcc50dc872d8",
   "metadata": {},
   "source": [
    "# Loop for generating a target type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5060748",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647eaba9-7e56-4528-b962-248d4f100389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "num_nonpattern = 5000  # Target patterning sets\n",
    "num_pattern = 5000 # Target patterning sets\n",
    "target_class = 1 # 1 ring\n",
    "col_names = scaling_ranges.keys()\n",
    "N = 10000 # Total number of random parameters to infer every loop\n",
    "\n",
    "for iii in tqdm(range(0, 400)):\n",
    "\n",
    "    # Randomly sample parameters\n",
    "    rand_params = random_sampling(scaling_ranges, scaling_options, col_names, N)\n",
    "    rand_params = scale_dataset(rand_params, scaling_ranges, scaling_options)    \n",
    "    params_tensor = torch.tensor(rand_params, dtype=torch.float32)\n",
    "\n",
    "    # Save and load\n",
    "    filename = os.path.join(output_dir, 'temp.txt')\n",
    "    np.savetxt(filename, params_tensor, delimiter=',', fmt='%0.8f')\n",
    "    params_tensor = np.loadtxt(filename, delimiter=',')\n",
    "    params_tensor = torch.tensor(params_tensor, dtype=torch.float32).to(device)\n",
    "  \n",
    "    # Get start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Predict \n",
    "    with torch.no_grad():\n",
    "        ML_outputs, _, _ = model(params_tensor)\n",
    "    end_time = time.time()\n",
    "\n",
    "    #  Total compute time\n",
    "    comp_time = end_time - start_time\n",
    "    comp_time_per_pred = comp_time/len(ML_outputs)\n",
    "    print(' **************************************************************** ')\n",
    "    print(f\"Comp time: {comp_time} seconds\")\n",
    "    print(f\"Averaged comp time: {comp_time_per_pred} seconds\")\n",
    "    print(str((iii + 1) * N) + ' data points have been generated so far')\n",
    "\n",
    "    ML_outputs = ML_outputs.cpu().numpy()\n",
    "    params_tensor = params_tensor.cpu()\n",
    "    \n",
    "    # print(' -------------------------- Smoothing -------------------------- ')\n",
    "    # ML_outputs = np.array(ML_outputs)\n",
    "    # for i in range(0, len(ML_outputs)):\n",
    "    #     data = ML_outputs[i, 0, :]\n",
    "    #     data = remove_rand_peaks(data, zero_threshold=0.05, min_zero_length=5, peak_threshold=0.1)\n",
    "    #     data = np.array(moving_average_filter(data, window_size=9)) \n",
    "    #     ML_outputs[i, 0, :] = data \n",
    "        \n",
    "    print(' ---------------------- Get pattern type ----------------------- ')\n",
    "    _, RFP_type_list = get_RFP_type(ML_outputs)\n",
    "    if_smooth_list = check_smoothness_dataset(ML_outputs)\n",
    "    \n",
    "    print('------------------------ Process by type ------------------------ ')\n",
    "    output_df = pd.DataFrame(params_tensor, columns=col_names)\n",
    "    output_df['if_smooth'] = if_smooth_list\n",
    "    output_df['RFP_type'] = RFP_type_list\n",
    "    output_df['ring_num'] = peak_to_ring_num(np.array(RFP_type_list))\n",
    "\n",
    "    # Remove nonsmooth predictions\n",
    "    output_df = output_df[output_df['if_smooth'] == 1]\n",
    "\n",
    "    # Get index for target type\n",
    "    RFP_target_idx = output_df[output_df['ring_num'] == target_class].index\n",
    "    print(len(RFP_target_idx))\n",
    "    print(' ************************ Save temp files ************************ ')\n",
    "    save_ML_by_type(idx, num_nonpattern, RFP_target_idx, ML_outputs, params_tensor, target_class, output_dir)\n",
    "\n",
    "    print(' ************************** Concatenate ************************** ')\n",
    "    num_target, target_df, concate_outputs = concatenate_temps_by_type(idx, num_pattern, target_class, col_names, output_dir)\n",
    "    \n",
    "    idx += 1\n",
    "    if num_target == num_pattern:\n",
    "        print('Finished!')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42fa394-5d6e-4b7f-bf55-2a2eee6bb9b2",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39001e6-80f4-41c9-81c6-afbffa36393a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the final dataset\n",
    "print(len(target_df))\n",
    "all_sets = target_df\n",
    "all_set_outputs = concate_outputs\n",
    "ML_all_outputs = np.vstack((all_set_outputs))\n",
    "ML_all_params = all_sets[col_names]\n",
    "ML_all_types = all_sets['RFP_type']\n",
    "\n",
    "# Save normalied parametrs\n",
    "filename = output_dir + 'ML_norm_params.npy'\n",
    "np.save(filename, np.array(ML_all_params)) \n",
    "filename = os.path.join(output_dir, 'ML_norm_params.txt')\n",
    "np.savetxt(filename, ML_all_params, delimiter=',', fmt='%0.8f')\n",
    "\n",
    "# Scale params\n",
    "ML_all_params = ML_all_params.to_numpy()\n",
    "ML_all_params = scaleback_dataset(ML_all_params, scaling_ranges, scaling_options)\n",
    "\n",
    "# Save\n",
    "filename = output_dir + 'ML_outputs.npy'\n",
    "np.save(filename, np.array(ML_all_outputs))\n",
    "filename = output_dir + 'ML_params.npy'\n",
    "np.save(filename, np.array(ML_all_params)) # not scaled back\n",
    "filename = output_dir + 'ML_types.npy'\n",
    "np.save(filename, np.array(ML_all_types))\n",
    "\n",
    "filename = os.path.join(output_dir, 'ML_params.txt')\n",
    "np.savetxt(filename, ML_all_params, delimiter=',', fmt='%0.8f')\n",
    "print(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
